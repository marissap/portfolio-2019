{"componentChunkName":"component---src-templates-blog-post-js","path":"/intro-to-neural-networks/","result":{"data":{"site":{"siteMetadata":{"title":"Software Engineer - Portfolio"}},"markdownRemark":{"id":"03c1ba98-6d51-59b3-bce0-8b3ad863bf2c","excerpt":"Light reaches your eyes, a neuron or thousand fire, and you see the words on the screen in front of you. On our scale, this happens instantaneously. It’s…","html":"<p>Light reaches your eyes, a neuron or thousand fire, and you see the words on the screen in front of you. On our scale, this happens instantaneously. It’s remarkable if you think about it. The brain can anticipate what will happen next, fill in the gaps, make thousands of computations in nanoseconds. <em>No wonder we want to replicate that process in computers.</em></p>\n<br>\n<p>One of the ways we attempt to replicate, what we actually understand so little of, is with artificial neural networks (ANN).</p>\n<br>\n<p>Neural networks are made up of simple, highly interconnected elements called perceptrons. They’re mathematical models meant to imitate neurons in the human brain. </p>\n<br>\n<p>Multiple inputs come in, the perceptron does some dynamic mathematical transformation, and outputs a value. In our brains, dendrites receive electrical signals and move them into the cell body. The nucleus computes and the axon carries the transformed signal out where it’s terminals neurotransmitter across the synapse.</p>\n<br>\n<p>In a neural network, we can think of synapses as a connection between perceptrons, represented by a line from perceptron to perceptron. In the brain, synapses modulate the electrical signals in different amounts. We can replicate that by assigning an influence value to each synapse. Called weights, they represent the weight of influence each input has on our model’s decision making.</p>\n<br>\n<p>Weights combine with inputs to generate a weighted sum. This is the sum of inputs after being multiplied with each of their respective weights. Finally, a function is applied to the weight generating the final output. This function is supposed to replicate the threshold which regulates neuron firing.</p>\n<br>\n<p>We can view the state of a neuron in terms of potential. There is the membrane potential, threshold potential, action potential, and resting potential. Each related to the distribution of electric charge within a neuron. Changes in distribution during the firing process are known as depolarization, repolarization, and hyperpolarization. Electrophysiological recordings graph this process as a polynomial curve. </p>\n<br>\n<p>To make the perceptron replicate the neuron as closely as possible, we have to apply a function to the weighted sum that can handle polynomials. These are called activation functions. </p>\n<br>\n<p>Activation functions are differentiable which means they can deal with polynomials and therefore, impose non-linearity onto the model. There are many functions to choose from but a common one is the Sigmoid function.</p>\n<br>\n<p>We have input values, weights, non-linear transformation, and output however, neural networks are used for deep <strong>learning</strong>. How does it <em>learn</em> from these components?</p>\n<br>\n<p><strong>Learning is an optimization problem.</strong> We are trying to minimize the <em>error</em> in our prediction.</p>\n<br>\n<p>Let’s say we send test data through and it comes out on the other side with a prediction far from our target value. We need to determine the error, modify something to minimize the error, and then try again to get closer to the target value.</p>\n<br>\n<p>Why would we be getting an error? We’ve weighted our inputs incorrectly, giving too much or too little influence to certain inputs. Therefore, minimizing the error is going to be related to changing the weights.</p>\n<br>\n<p>Our optimization problem is as follows, minimize the error by changing the weights. We can do this with an algorithm called Gradient Descent. It finds a local minimum of a differentiable function. This is why activation functions are so important.  If we had a network using a step function on the weighted sum, we’d only be able to generate 0 or 1 which won’t help us modify the weights.</p>\n<br>\n<p>Gradient descent finds the derivative of the error with respect to each weight. Each differentiation gives us a new weight which will move us closer to a local minimum.</p>\n<br>\n<p>We continue this process of differentiating and modifying weights until the prediction is the best approximation of the target value. <strong>This iterative process is the model learning.</strong></p>\n<br>\n<p>That is a simple walkthrough of neural networks used in deep learning. If you want to see the math behind it and code that implements it, you can head to this jupyter notebook. The key takeaway from this article is as follows:</p>\n<br>\n<blockquote>\n<p>The main objective of a neural network is to find the value of each weight to produce predictions as close as possible to the target value.</p>\n</blockquote>","frontmatter":{"title":"An Introduction to Neural Networks","date":"October 20, 2020","description":"Walking through the brain, artificially speaking.","image":{"childImageSharp":{"resize":{"src":"/static/c6358af28cdd75994f97c6a650108f07/47498/featured.jpg","height":798,"width":1200}}}}}},"pageContext":{"slug":"/intro-to-neural-networks/","readingTime":"4 min read","previous":{"fields":{"slug":"/not-gpt3/","readingTime":{"text":"5 min read"}},"frontmatter":{"title":"This was not written by GPT-3"}},"next":null}}}